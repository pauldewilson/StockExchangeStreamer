{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad94bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import time\n",
    "import json\n",
    "import shutil\n",
    "import os\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from datetime import timedelta\n",
    "from datetime import datetime as dt\n",
    "from pyspark import SparkContext, SparkConf, SparkFiles\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, TimestampType, ArrayType\n",
    "from IPython.display import clear_output\n",
    "from delta import *\n",
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b08c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = pyspark.sql.SparkSession.builder.appName(\"MyApp\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.default.parallelism\", \"24\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44df6e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.DIR_ROOT = os.getcwd()+\"\\sx\"\n",
    "        self.DIR_COMPANIES = os.path.join(self.DIR_ROOT, \"companies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadb9ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV = Environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15728127",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"ticker\", StringType(), True),\n",
    "    StructField(\"price\", DoubleType(), True),\n",
    "    StructField(\"timestamp\", TimestampType(), True),\n",
    "])\n",
    "\n",
    "while True:\n",
    "    time.sleep(5)\n",
    "    df = spark.read.json(os.path.join(ENV.DIR_COMPANIES, \"*\", \"trades\", \"*.json\"), schema=schema).orderBy([\"ticker\", \"timestamp\"])\n",
    "    df.write.mode(\"overwrite\").format(\"delta\").save(os.path.join(ENV.DIR_ROOT, \"delta\",\"trades\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6be2a75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "2ab3d203e2c92172551cf398990812d139b1200d959eee68d18edd0d3f927067"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
